####################################################################################################
#
# FinalQualityFiltering.R
#
# 18 August 2019
#
# Created by Steph Szarmach
# Northern Michigan University
#
# This script can be used to summarize output from the RADGenotypes.py program in the DaCosta and
# Sorenson (2014) ddRAD-seq pipeline and generate a final data set of quality-filtered RAD loci. 
#
####################################################################################################

library(tidyverse)

#Set working directory to folder containing RADGenotypes.py output files
setwd("~/WildebeestProject/DataAnalysis/DaCostaSorensonPipeline/Genotyping/WildebeestBLASTedDataset")

#Read *clustersummary.out file generated by RADGenotypes.py (Converted to .csv format in Excel)
clustersum = read.csv("n76clustersummary_wbBlasted.csv")
clustersum$Clstr = as.character(clustersum$Clstr)
clustersum$Pos = as.numeric(clustersum$Pos)
clustersum$Dir = as.factor(clustersum$Dir)
clustersum$Edit = as.factor(clustersum$Edit)

### POLYMORPHIC LOCI ##############################################################################

#Number of loci with no variation
clustersum %>%
  filter(Poly == 0) %>%
  summarise(NoVar = n()) 
#Number of loci with at least one SNP
clustersum %>%
  filter(SNPS > 0) %>%
  summarise(filtered1 = n()) 
#Number of loci with at least one indel and no SNPs
clustersum %>%
  filter(Gaps > 0 & SNPS == 0) %>%
  summarise(indelOnly = n()) 

#Filter to include only loci that contain at least one SNP
filtered1 = clustersum %>%
  filter(SNPS > 0)
filtered1$Clstr = as.factor(filtered1$Clstr)
filtered1$Pos = as.numeric(filtered1$Pos)
filtered1$Dir = as.factor(filtered1$Dir)
filtered1$Edit = as.factor(filtered1$Edit)

### MISSING DATA ###################################################################################

#Remove loci with >10% missing genotypes
#Total number of individuals with "no data" (code 0) or "low depth" (code 2) genotypes at a locus 
#should not be more than 10% of the total number of individuals

filtered2 = filtered1 %>%
  filter((NoData + LowDepth) < 8) #Replace 8 with (.10)*n, rounded up

### FLAGGED GENOTYPES #####################################################################################

#Remove loci with >5% flagged genotypes
#Total number of individuals with genotypes flagged as code 3 (bad ratio), 4 (extra reads), or 5 (3rd allele)
#should not be more than 5% of the total number of individuals

filtered3 = filtered2 %>%
  filter((BadRatio + ExtraReads + X3rdAllele) < 4) #Replace 4 with (.05)*n, rounded up

### EXCESS HETEROZYGOSITY #################################################################################

#Remove loci with heterozygosity > 0.5 that deviate from HW equilibrium
#Sign that cluster was erroneously formed between paralagous loci
#Reject the HW null hypothesis if Chi-Squared is greater than 3.841

#Which loci have high heterozygosity?
HiHet = filtered2 %>%
  filter(Hets > 38) #Replace 38 with (0.5)*n

#Which high-heterozygosity loci deviate from Hardy-Weinberg expectations?
HiHet_failHW = HiHet %>%
  filter(HW.X2 > 3.841)

#Filter out high-het loci that fail HW
filtered4 = setdiff(filtered3, HiHet_failHW)

### HIGH DEPTH ############################################################################################

#Abnormally high depth is a sign that cluster was erroneously formed between paralagous loci

#Select columns of cluster summary table reporting depth per locus
locusdepth = filtered4 %>%
  select(Clstr, 27:102) #Will need to change selection range depending on sample size and cluster summary file
#Gather from wide format to long format
longdepth = locusdepth %>% 
  gather(Sample, Depth, -Clstr, factor_key = TRUE)
#Calculate depth per locus averaged over all samples
PerSampleLocusDepth = longdepth %>%
  group_by(Clstr) %>%
  summarise(mean_depth = mean(Depth))
#Order clusters numerically
PerSampleLocusDepth$Clstr = as.numeric(PerSampleLocusDepth$Clstr)
PerSampleLocusDepth = PerSampleLocusDepth[order(PerSampleLocusDepth$Clstr),]

#Create histogram of mean depth per locus 
ggplot(PerSampleLocusDepth) +
  geom_histogram(mapping=aes(mean_depth))
#Look for secondary peak of high-depth loci or high-depth outliers

#Remove high-depth outlier loci
HighDepth = PerSampleLocusDepth %>% 
  filter(mean_depth > 700) #Replace 700 with depth above which loci are considered high-depth outliers
HighDepth$Clstr = as.factor(HighDepth$Clstr)
filtered5 = anti_join(filtered4, HighDepth, by="Clstr")

### EXCESS HOMOZYGOSITY ##########################################################################################################

#Remove loci that deviate from HW equilibrium due to excess homozygosity
#Sign that cluster was erroneously formed between paralagous loci
#Reject the HW null hypothesis if Chi-Squared is greater than 3.841

failHW = filtered5 %>%
  filter(HW.X2 > 3.841)

filtered6 = anti_join(filtered5, failHW, by="Clstr")

### INFINITE SITES MODEL ######################################################################################################### 

#Filter out loci that do not meet the expectations of the infinite sites model 

FailIS = filtered6 %>%
  filter(InfSites == FALSE)

filtered7 = filtered6 %>%
  filter(InfSites == TRUE)

### HIGH POLYMORPHISM ######################################################################################################

#Remove loci with more than 4 SNPs - likely to be incorrectly clustered paralogous loci

filtered8 = filtered7 %>%
  filter(SNPS < 5)

### FILTER OUT LOCI THAT FAILED MANUAL CHECKS  #################################################################################

#The DaCosta and Sorenson pipeline assigns clusters edit codes, as needed, to indicate whether a cluster was edited
#automatically by the program, or if a cluster should be manually checked for alignment errors. I manually checked 
#the sequences in clusters flagged with codes 1-6 in MEGA and created an Excel spreadsheet reporting whether the
#cluster should be removed or retained in the analysis.

#How many loci should be manually checked (Edit code 1-6)?
ManualCheck = filtered8 %>%
  filter(Edit %in% c("1","1.1","2","2.1","2.8","2.9","3.7","4","4.7","4.712","5","5.7","7.1","7.22","7.92","11.2"))

#Read in .csv files listing which manually checked clusters should be removed or retained
manualcheck1 = read.csv("ManualEditLoci1.csv") #Results from manual checks based on edit codes
manualcheck2 = read.csv("ManualEditLoci2.csv") #Results from manual checks based on polymorphism or cSNP issues

#Identify loci that failed manual checks
mancheck1_fail = manualcheck1 %>%
  filter(Retain == "N")
mancheck1_fail$Clstr = as.factor(mancheck1_fail$Clstr)
mancheck2_fail = manualcheck2 %>%
  filter(Retain == "N")
mancheck2_fail$Clstr = as.factor(mancheck2_fail$Clstr)

#Remove loci that did not pass manual checks
filtered9 = anti_join(filtered8, mancheck1_fail, by = "Clstr")
filtered9 = anti_join(filtered9, mancheck2_fail, by = "Clstr")

### BLAST ALIGNMENT TO REFERENCE GENOME ################################################################################

#I manually checked loci that generated multiple BLAST hits to the reference genome. Most loci with multiple
#BLAST hits were removed. The DaCosta and Sorenson pipeline assigns clusters a code (one, one+, multiple, tied, tied+)
#to describe the number and quality of BLAST hits.

#Summarize BLAST Hit Codes
filtered9 %>%
  group_by(Hits) %>%
  summarise(HitCodes = n())

#remove "multiple", "tied", "tied+" - all of these loci have multiple equally good BLAST hits
filtered10 = filtered9 %>%
  filter(!Hits %in% c("tied", "tied+", "multiple"))

#Create list of all loci that generated "best" or "one+" result codes for manual checks
MultipleHits = filtered10 %>%
  filter(Hits %in% c("one+", "best"))
write.csv(MultipleHits, "MultipleHits_Check.csv")

#Remove loci that failed manual check
MultipleHits_Remove = read.csv("MultipleHitsCheck_Remove.csv")
MultipleHits_Remove$Clstr = as.factor(MultipleHits_Remove$Clstr)
filtered11 = anti_join(filtered9, MultipleHits_Remove, by = "Clstr")

#Remove miscellaneous problem loci (loci with third alleles and bad ratios that aligned to repetitive elements, low depth)
filtered12 = filtered11 %>%
  filter(!Clstr %in% c(1822, 4121, 5388, 6003, 9417, 11450, 452591, 452605, 475634))

### REMOVE SEX-LINKED LOCI #################################################################################################

#Loci on the X chromosome not useful for population level diversity measures - will be homozygous in all males
#Identified using sheep genome (no X chromosome identified for WB, only scaffolds)

#Read in cluster summary file for loci aligned to the sheep genome
sheep_sum = read.csv("n76WB_GenotypeSummary_SheepBlasted.csv")

#Identify loci that aligned to the sheep X-chromosome
Xchr = sheep_sum %>%
  filter(Chr == "NC_019484.2")
Xchr$Clstr = as.factor(Xchr$Clstr)

#Remove loci that aligned to the sheep X-chromosome from data set
filtered13= anti_join(filtered12, Xchr, by="Clstr")

#Write .csv file containing only loci that passed quality filtering steps
write.csv(filtered13, "FinalLoci.csv")

### DEPTH PER SAMPLE ########################################################################################################

#After running through quality filtering steps, calculate average depth per locus for each sample.
#Samples with a mean depth per locus < 10 should be removed from the analysis. 
#RADGenotypes.py and the quality filtering pipeline should be rerun on the remaining samples. Removing low-depth samples can 
#allow more loci to be retained, because they will be genotyped in a greater proportion of the remaining samples. 

final_loci = read.csv("FinalLoci.csv")

#Select columns of cluster summary table reporting depth per locus
locusdepth = final_loci %>%
  select(Clstr, 27:102) #Will need to change selection range depending on sample size and cluster summary file

#Gather from wide format to long format
longdepth = locusdepth %>% 
  gather(factor_key = TRUE) %>%
  filter(key != "Clstr") 
colnames(longdepth)[colnames(longdepth)=="key"] <- "Sample"
colnames(longdepth)[colnames(longdepth)=="value"] <- "Depth"
longdepth$Depth = as.numeric(longdepth$Depth)

#Calculate average depth per locus for each sample
avgDepths = longdepth %>% 
  group_by(Sample) %>%
  summarise(avgDepth = mean(Depth))

#Identify low depth samples
LowDepth = avgDepths %>%
  filter(avgDepth < 10)

#Create bar plot of average depth per locus for each sample
avgDepths$Sample = factor(avgDepths$Sample, levels = avgDepths$Sample[order(-avgDepths$avgDepth)])
options(scipen=10000)
avgreads = ggplot(data=avgDepths) +
  geom_col(mapping=aes(x=Sample, y=avgDepth)) +
  xlab("Sample ID") +
  ylab("Average Depth Per Locus") +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  theme(axis.title.x = element_text(face="bold", size=14)) +
  theme(axis.title.y = element_text(face="bold", size=14))

### MINOR ALLELE FREQUENCY FILTER ###########################################################################################

#When converting .out genotype file from DaCosta and Sorenson pipeline to other file formats, you can select a minor allele
#frequency threshold to impose. The following code will update your final list of loci by removing clusters that did not pass
#the minor allele frequency filter.

#Read in file containing loci that passed quality filtering steps
Final = read.csv("FinalLoci.csv")

#Read in file containing cluster IDs of loci that remained after minor allele frequency filter
Final_MAF = read.csv("Final_MAF.csv")

#Include only loci that passed the minor allele frequency filter in your final cluster summary file
Final_MAF = semi_join(Final, Final_MAF, by="Clstr")

write.csv(Final_MAF, "Final_MAF.csv")
